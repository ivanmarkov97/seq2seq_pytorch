{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_seq2seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQQgBq2XOeI"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import functools\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext import datasets\r\n",
        "from torchtext.data import Field\r\n",
        "from torchtext.data import BucketIterator\r\n",
        "\r\n",
        "\r\n",
        "SEED = 241"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjjlEc0EYPpQ"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "  random.seed(seed)\r\n",
        "  np.random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "\r\n",
        "  if torch.cuda.is_available(): \r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ihF3iJYQ58",
        "outputId": "bb6cd41e-9af5-4ccc-d18f-a308efe376df"
      },
      "source": [
        "import spacy\r\n",
        "\r\n",
        "!python -m spacy download de --quiet\r\n",
        "!python -m spacy download en --quiet\r\n",
        "\r\n",
        "spacy_de = spacy.load('de')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.9MB 8.1MB/s \n",
            "\u001b[?25h  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUY6YitYSjb"
      },
      "source": [
        "def tokenize_de(text):\r\n",
        "  return [token.text for token in spacy_de.tokenizer(text)][::-1]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "  return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9sGjqN2YUVV"
      },
      "source": [
        "SRC = Field(lower=True,\r\n",
        "            use_vocab=True, \r\n",
        "            sequential=True, \r\n",
        "            init_token='<sos>',\r\n",
        "            eos_token='<eos>',\r\n",
        "            batch_first=True,\r\n",
        "            include_lengths=True,\r\n",
        "            tokenize=tokenize_de)\r\n",
        "\r\n",
        "TRG = Field(lower=True, \r\n",
        "            use_vocab=True,\r\n",
        "            sequential=True,\r\n",
        "            init_token='<sos>',\r\n",
        "            eos_token='<eos>',\r\n",
        "            batch_first=True,\r\n",
        "            include_lengths=True,\r\n",
        "            tokenize=tokenize_en)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adAMjXX6YVs2",
        "outputId": "392d1bea-0a80-478d-96e5-113152b754f9"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.Multi30k.splits(exts=('.de', '.en'),\r\n",
        "                                                             fields=[('de', SRC), ('en', TRG)])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 636kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 172kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 166kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY1169UzYcAO"
      },
      "source": [
        "SRC.build_vocab(train_data)\r\n",
        "TRG.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITEoWEMOYdc3"
      },
      "source": [
        "batch_size = 256\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "\r\n",
        "train_iterator = BucketIterator.splits((train_data,), batch_size=batch_size, device=device)[0]\r\n",
        "valid_iterator = BucketIterator.splits((valid_data,), batch_size=batch_size, device=device)[0]\r\n",
        "test_iterator = BucketIterator.splits((test_data,), batch_size=batch_size, device=device)[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKt4CFC3Yhrd"
      },
      "source": [
        "class Config:\r\n",
        "  def __init__(self,\r\n",
        "               vocab_size,\r\n",
        "               emb_size,\r\n",
        "               hidden_size,\r\n",
        "               num_layers, \r\n",
        "               dropout, \r\n",
        "               pad_index,\r\n",
        "               device):\r\n",
        "    self.vocab_size = vocab_size\r\n",
        "    self.emb_size = emb_size\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.num_layers = num_layers\r\n",
        "    self.dropout = dropout\r\n",
        "    self.pad_index = pad_index\r\n",
        "    self.device = device"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDuf2o_WYjXL"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, config):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(config.vocab_size,\r\n",
        "                                  config.emb_size, \r\n",
        "                                  padding_idx=config.pad_index)\r\n",
        "    self.dropout = nn.Dropout(config.dropout)\r\n",
        "    self.rnn = nn.LSTM(config.emb_size,\r\n",
        "                       config.hidden_size, \r\n",
        "                       config.num_layers, \r\n",
        "                       batch_first=True,\r\n",
        "                       bidirectional=True,\r\n",
        "                       dropout=config.dropout)\r\n",
        "    self.fc = nn.Linear(2 * config.hidden_size, config.hidden_size)\r\n",
        "    self.device = config.device\r\n",
        "\r\n",
        "  def forward(self, text, text_lens):\r\n",
        "    text_embedded = self.dropout(self.embedding(text))\r\n",
        "    packed_sequence = nn.utils.rnn.pack_padded_sequence(text_embedded, \r\n",
        "                                                        text_lens,\r\n",
        "                                                        batch_first=True, \r\n",
        "                                                        enforce_sorted=False)\r\n",
        "    \r\n",
        "    packed_outputs, (orig_hidden, cell) = self.rnn(packed_sequence)\r\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\r\n",
        "\r\n",
        "    hidden = torch.cat([orig_hidden[-1, :, :], orig_hidden[-2, :, :]], dim=1)\r\n",
        "    hidden = torch.tanh(self.fc(hidden))\r\n",
        "\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXLWU932axp3"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, enc_hidden_dim, dec_hidden_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.enc_hidden_dim = enc_hidden_dim\r\n",
        "    self.dec_hidden_dim = dec_hidden_dim\r\n",
        "    self.attention = nn.Linear((2 * self.enc_hidden_dim) + self.dec_hidden_dim, self.dec_hidden_dim)\r\n",
        "    self.v = nn.Linear(self.dec_hidden_dim, 1, bias=False)\r\n",
        "\r\n",
        "  def forward(self, hidden, enc_outputs, mask):\r\n",
        "    # hidden [bs, d_h_dim]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    bs, seq_len, _ = enc_outputs.shape\r\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\r\n",
        "    # hidden [bs, seq_len, d_h_dim]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    attn = torch.tanh(self.attention(torch.cat([hidden, enc_outputs], dim=2)))\r\n",
        "    # attn [bs, seq_len, d_h_dim]\r\n",
        "    energy = self.v(attn)\r\n",
        "    # energy [bs, seq_len, 1]\r\n",
        "    energy = energy.squeeze(2)\r\n",
        "    # energy [bs, seq_len]\r\n",
        "    energy = energy.masked_fill(mask == 0, -1e6)\r\n",
        "    return F.softmax(energy, dim=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKMch61Vjd5Z"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, config, attention, enc_hidden_size):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(config.vocab_size, \r\n",
        "                                  config.emb_size, \r\n",
        "                                  padding_idx=config.pad_index)\r\n",
        "    self.dropout = nn.Dropout(config.dropout)\r\n",
        "    self.rnn = nn.GRU(config.emb_size + 2 * enc_hidden_size,\r\n",
        "                       config.hidden_size,\r\n",
        "                       config.num_layers,\r\n",
        "                       batch_first=True, \r\n",
        "                       dropout=config.dropout if config.num_layers > 1 else 0)\r\n",
        "    self.device = config.device\r\n",
        "    self.output_dim = config.vocab_size\r\n",
        "    self.attention = attention\r\n",
        "    self.enc_hidden_size = enc_hidden_size\r\n",
        "    self.output = nn.Linear(config.hidden_size + config.emb_size + (2 * enc_hidden_size), config.vocab_size)\r\n",
        "\r\n",
        "  def forward(self, trg_input, hidden, enc_outputs, mask):\r\n",
        "    trg_input = trg_input.unsqueeze(1)\r\n",
        "    # trg_input [bs, 1]\r\n",
        "    text_embedded = self.dropout(self.embedding(trg_input))\r\n",
        "    # text_embedded [bs, 1, emb_dim]\r\n",
        "\r\n",
        "    attn = self.attention(hidden, enc_outputs, mask)\r\n",
        "    # attn [bs, seq_len]\r\n",
        "    attn = attn.unsqueeze(1)\r\n",
        "    # attn [bs, 1, seq_len]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    weights = torch.bmm(attn, enc_outputs)\r\n",
        "    # weights [bs, 1, 2 * e_h_dim]\r\n",
        "    rnn_input = torch.cat([text_embedded, weights], dim=2)\r\n",
        "    # rnn_input [bs, 1, 2 * e_h_dim + emb_dim]\r\n",
        "    hidden = hidden.unsqueeze(0)\r\n",
        "    # hidden [1, bs, h_dim]\r\n",
        "    outputs, hidden = self.rnn(rnn_input, hidden)\r\n",
        "    # outputs [bs, 1, d_h_dim]\r\n",
        "    # hidden_orig [1, bs, d_h_dim]\r\n",
        "    hidden = hidden.squeeze(0)\r\n",
        "    text_embedded = text_embedded.squeeze(1)\r\n",
        "    weights = weights.squeeze(1)\r\n",
        "\r\n",
        "    outputs = torch.cat([hidden, text_embedded, weights], dim=1)\r\n",
        "    # outputs [bs, 1, d_h_dim + emb_size + 2 * e_h_dim]\r\n",
        "    return self.output(outputs), hidden, attn"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHP7lT8snvhV"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, encoder, decoder, device):\r\n",
        "    super().__init__()\r\n",
        "    self.encoder = encoder\r\n",
        "    self.decoder = decoder\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "  def _create_mask(self, src_text_lens):\r\n",
        "    bs = src_text_lens.size(0)\r\n",
        "    max_src_seq_len = torch.max(src_text_lens)\r\n",
        "    mask = torch.zeros(bs, max_src_seq_len)\r\n",
        "    for i in range(bs):\r\n",
        "      mask[i, :src_text_lens[i]] = 1\r\n",
        "    return mask\r\n",
        "\r\n",
        "  def forward(self, \r\n",
        "              src_text,\r\n",
        "              src_text_len,\r\n",
        "              trg_text,\r\n",
        "              trg_text_len,\r\n",
        "              teacher_forcing_ratio=0.5):\r\n",
        "    \r\n",
        "    enc_outputs, hidden = self.encoder(src_text, src_text_len)\r\n",
        "    bs, seq_len = trg_text.shape\r\n",
        "    dec_output_dim = decoder.output_dim\r\n",
        "    mask = self._create_mask(src_text_len)\r\n",
        "    mask = mask.to(self.device)\r\n",
        "\r\n",
        "    outputs = torch.zeros(bs, seq_len, dec_output_dim).to(self.device)\r\n",
        "\r\n",
        "    trg_input = trg_text[:, 0]\r\n",
        "\r\n",
        "    for t in range(1, seq_len):\r\n",
        "      prediction, hidden, attn = decoder(trg_input, hidden, enc_outputs, mask)\r\n",
        "\r\n",
        "      outputs[:, t, :] = prediction\r\n",
        "\r\n",
        "      top1 = torch.argmax(prediction, dim=1)\r\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "      next_token = trg_text[:, t]\r\n",
        "\r\n",
        "      trg_input = next_token if teacher_force else top1\r\n",
        "    return outputs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wpqPQb5Zhbz"
      },
      "source": [
        "encoder_config = Config(vocab_size=len(SRC.vocab),\r\n",
        "                        emb_size=512,\r\n",
        "                        hidden_size=256,\r\n",
        "                        num_layers=2,\r\n",
        "                        dropout=0.3,\r\n",
        "                        pad_index=SRC.vocab.stoi[SRC.pad_token],\r\n",
        "                        device=device)\r\n",
        "\r\n",
        "decoder_config = Config(vocab_size=len(TRG.vocab),\r\n",
        "                        emb_size=512,\r\n",
        "                        hidden_size=256,\r\n",
        "                        num_layers=1,\r\n",
        "                        dropout=0.3,\r\n",
        "                        pad_index=TRG.vocab.stoi[TRG.pad_token],\r\n",
        "                        device=device)\r\n",
        "\r\n",
        "encoder = Encoder(encoder_config)\r\n",
        "attention = Attention(encoder_config.hidden_size, decoder_config.hidden_size)\r\n",
        "decoder = Decoder(decoder_config, attention, encoder_config.hidden_size)\r\n",
        "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=decoder_config.pad_index).to(device)\r\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZYaHbxmZkvT"
      },
      "source": [
        "# with torch.no_grad():\r\n",
        "#   for batch in train_iterator:\r\n",
        "#     src_text, src_text_len = batch.de\r\n",
        "#     trg_text, trg_text_len = batch.en\r\n",
        "\r\n",
        "#     outputs = seq2seq(src_text, src_text_len, trg_text, trg_text_len)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNVaUvAAjZqJ"
      },
      "source": [
        "def train_epoch(model, iterator, optimizer, criterion, teacher_force=0.5):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  error = 0.\r\n",
        "  for batch in iterator:\r\n",
        "    optimizer.zero_grad()\r\n",
        "    \r\n",
        "    src_text, src_text_lens = batch.de\r\n",
        "    src_text_lens = src_text_lens.cpu()\r\n",
        "    trg_text, trg_text_lens = batch.en\r\n",
        "    trg_text_lens = trg_text_lens.cpu()\r\n",
        "\r\n",
        "    outputs = seq2seq(src_text, src_text_lens, trg_text, trg_text_lens, teacher_forcing_ratio=teacher_force)\r\n",
        "\r\n",
        "    outputs = outputs[:, 1:, :]\r\n",
        "    trg_text = trg_text[:, 1:]\r\n",
        "\r\n",
        "    outputs = outputs.contiguous()\r\n",
        "    trg_text = trg_text.contiguous()\r\n",
        "\r\n",
        "    batch_size, seq_len, output_dim = outputs.shape\r\n",
        "\r\n",
        "    outputs = outputs.view(-1, output_dim)\r\n",
        "    trg_text = trg_text.view(-1)\r\n",
        "\r\n",
        "    loss = criterion(outputs, trg_text)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "    error += loss.detach().cpu().numpy()\r\n",
        "\r\n",
        "  return error / len(iterator)\r\n",
        "\r\n",
        "\r\n",
        "def valid_epoch(model, iterator, criterion, teacher_force=0):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  error = 0.\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch in iterator:\r\n",
        "      \r\n",
        "      src_text, src_text_lens = batch.de\r\n",
        "      src_text_lens = src_text_lens.cpu()\r\n",
        "      trg_text, trg_text_lens = batch.en\r\n",
        "      trg_text_lens = trg_text_lens.cpu()\r\n",
        "\r\n",
        "      outputs = seq2seq(src_text, src_text_lens, trg_text, trg_text_lens, teacher_forcing_ratio=teacher_force)\r\n",
        "\r\n",
        "      outputs = outputs[:, 1:, :]\r\n",
        "      trg_text = trg_text[:, 1:]\r\n",
        "\r\n",
        "      outputs = outputs.contiguous()\r\n",
        "      trg_text = trg_text.contiguous()\r\n",
        "\r\n",
        "      batch_size, seq_len, output_dim = outputs.shape\r\n",
        "\r\n",
        "      outputs = outputs.reshape(-1, output_dim)\r\n",
        "      trg_text = trg_text.view(-1)\r\n",
        "\r\n",
        "      loss = criterion(outputs, trg_text)\r\n",
        "\r\n",
        "      error += loss.detach().cpu().numpy()\r\n",
        "\r\n",
        "  return error / len(iterator)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "tPJVoSv5yROF",
        "outputId": "2a8a4c71-41a7-42d0-f183-8fd7efe6410b"
      },
      "source": [
        "for i in range(10):\r\n",
        "  train_error = train_epoch(seq2seq, train_iterator, optimizer, criterion, teacher_force=0.5)\r\n",
        "  valid_error = valid_epoch(seq2seq, valid_iterator, criterion, teacher_force=0)\r\n",
        "  print(f'Epoch: {i + 1}, Train Error: {train_error}, Valid Error {valid_error}')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Error: 1.7367130612072192, Valid Error 3.6825554370880127\n",
            "Epoch: 2, Train Error: 1.637947426553358, Valid Error 3.680503249168396\n",
            "Epoch: 3, Train Error: 1.575768390245605, Valid Error 3.7186837792396545\n",
            "Epoch: 4, Train Error: 1.4883824471841778, Valid Error 3.716822564601898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-7672ad766acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mvalid_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {i + 1}, Train Error: {train_error}, Valid Error {valid_error}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-29eafdd06516>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, iterator, optimizer, criterion, teacher_force)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jj7AidXJRtm"
      },
      "source": [
        "# class LanguageModel:\r\n",
        "\r\n",
        "#   def __init__(self):\r\n",
        "#     self.key_sep = '&'\r\n",
        "#     self._occurances = {}\r\n",
        "\r\n",
        "#   def build(self, texts):\r\n",
        "#     for text in texts:\r\n",
        "#       self.update(text)\r\n",
        "\r\n",
        "#   def update(self, text):\r\n",
        "#     tokens = text.split()\r\n",
        "#     for i in range(len(tokens) - 1):\r\n",
        "#       key = f'{tokens[i]}{self.key_sep}{tokens[i + 1]}'\r\n",
        "#       if key not in self._occurances:\r\n",
        "#         self._occurances[key] = 1\r\n",
        "#       else:\r\n",
        "#         self._occurances[key] += 1\r\n",
        "  \r\n",
        "#   def get(self, word, next_word):\r\n",
        "#     key = f'{word}{self.key_sep}{next_word}'\r\n",
        "#     if key not in self._occurances:\r\n",
        "#       return 0\r\n",
        "#     else:\r\n",
        "#       return self._occurances[key] / len(self._occurances)\r\n",
        "\r\n",
        "\r\n",
        "# lang_model = LanguageModel()\r\n",
        "# corpus = [' '.join(example.en) for example in train_data.examples]\r\n",
        "# lang_model.build(corpus)\r\n",
        "\r\n",
        "# lang_model.get(word='two', next_word='men')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slr1D18olt_I"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)][::-1]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence][::-1]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token] \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\r\n",
        "\r\n",
        "    mask = torch.ByteTensor([1.] * len(src_indexes)).to(device)\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\r\n",
        "\r\n",
        "        attentions[i] = attention\r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT0PEEAvFTMH",
        "outputId": "1442f9e6-f517-4c15-c914-03ccab0b2584"
      },
      "source": [
        "index = 2\r\n",
        "\r\n",
        "print(' '.join(train_data.examples[index].en))\r\n",
        "trg_tokens, attentions_scores = translate_sentence(' '.join(train_data.examples[index].de[::-1]), SRC, TRG, seq2seq, device)\r\n",
        "if trg_tokens[-1] == TRG.eos_token:\r\n",
        "  trg_tokens = trg_tokens[:-1]\r\n",
        "print(' '.join(trg_tokens))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a little girl climbing into a wooden playhouse .\n",
            "a little girl is climbing into a wooden playhouse .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh1nTZwHFVIF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
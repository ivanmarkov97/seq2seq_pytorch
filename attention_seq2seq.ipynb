{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_seq2seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQQgBq2XOeI"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import functools\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext import datasets\r\n",
        "from torchtext.data import Field\r\n",
        "from torchtext.data import BucketIterator\r\n",
        "\r\n",
        "\r\n",
        "SEED = 241"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjjlEc0EYPpQ"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "  random.seed(seed)\r\n",
        "  np.random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "\r\n",
        "  if torch.cuda.is_available(): \r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "seed_everything(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ihF3iJYQ58",
        "outputId": "94cd40c9-3931-48af-982d-d44ce2f2d228"
      },
      "source": [
        "import spacy\r\n",
        "\r\n",
        "!python -m spacy download de --quiet\r\n",
        "!python -m spacy download en --quiet\r\n",
        "\r\n",
        "spacy_de = spacy.load('de')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUY6YitYSjb"
      },
      "source": [
        "def tokenize_de(text):\r\n",
        "  return [token.text for token in spacy_de.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "  return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9sGjqN2YUVV"
      },
      "source": [
        "SRC = Field(lower=True,\r\n",
        "            use_vocab=True, \r\n",
        "            sequential=True, \r\n",
        "            init_token='<sos>',\r\n",
        "            eos_token='<eos>',\r\n",
        "            batch_first=True,\r\n",
        "            include_lengths=True,\r\n",
        "            tokenize=tokenize_de)\r\n",
        "\r\n",
        "TRG = Field(lower=True, \r\n",
        "            use_vocab=True,\r\n",
        "            sequential=True,\r\n",
        "            init_token='<sos>',\r\n",
        "            eos_token='<eos>',\r\n",
        "            batch_first=True,\r\n",
        "            include_lengths=True,\r\n",
        "            tokenize=tokenize_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adAMjXX6YVs2"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.Multi30k.splits(exts=('.de', '.en'),\r\n",
        "                                                             fields=[('de', SRC), ('en', TRG)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY1169UzYcAO"
      },
      "source": [
        "SRC.build_vocab(train_data)\r\n",
        "TRG.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITEoWEMOYdc3"
      },
      "source": [
        "batch_size = 256\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "\r\n",
        "train_iterator = BucketIterator.splits((train_data,), batch_size=batch_size, device=device)[0]\r\n",
        "valid_iterator = BucketIterator.splits((valid_data,), batch_size=batch_size, device=device)[0]\r\n",
        "test_iterator = BucketIterator.splits((test_data,), batch_size=batch_size, device=device)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKt4CFC3Yhrd"
      },
      "source": [
        "class Config:\r\n",
        "  def __init__(self,\r\n",
        "               vocab_size,\r\n",
        "               emb_size,\r\n",
        "               hidden_size,\r\n",
        "               num_layers, \r\n",
        "               dropout, \r\n",
        "               pad_index,\r\n",
        "               device):\r\n",
        "    self.vocab_size = vocab_size\r\n",
        "    self.emb_size = emb_size\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.num_layers = num_layers\r\n",
        "    self.dropout = dropout\r\n",
        "    self.pad_index = pad_index\r\n",
        "    self.device = device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDuf2o_WYjXL"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, config):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(config.vocab_size,\r\n",
        "                                  config.emb_size, \r\n",
        "                                  padding_idx=config.pad_index)\r\n",
        "    self.dropout = nn.Dropout(config.dropout)\r\n",
        "    self.rnn = nn.LSTM(config.emb_size,\r\n",
        "                       config.hidden_size, \r\n",
        "                       config.num_layers, \r\n",
        "                       batch_first=True,\r\n",
        "                       bidirectional=True,\r\n",
        "                       dropout=config.dropout)\r\n",
        "    self.fc = nn.Linear(2 * config.hidden_size, config.hidden_size)\r\n",
        "    self.device = config.device\r\n",
        "\r\n",
        "  def forward(self, text, text_lens):\r\n",
        "    text_embedded = self.dropout(self.embedding(text))\r\n",
        "    packed_sequence = nn.utils.rnn.pack_padded_sequence(text_embedded, \r\n",
        "                                                        text_lens,\r\n",
        "                                                        batch_first=True, \r\n",
        "                                                        enforce_sorted=False)\r\n",
        "    \r\n",
        "    packed_outputs, (orig_hidden, cell) = self.rnn(packed_sequence)\r\n",
        "    outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\r\n",
        "\r\n",
        "    hidden = torch.cat([orig_hidden[-1, :, :], orig_hidden[-2, :, :]], dim=1)\r\n",
        "    hidden = torch.tanh(self.fc(hidden))\r\n",
        "\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXLWU932axp3"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, enc_hidden_dim, dec_hidden_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.enc_hidden_dim = enc_hidden_dim\r\n",
        "    self.dec_hidden_dim = dec_hidden_dim\r\n",
        "    self.attention = nn.Linear((2 * self.enc_hidden_dim) + self.dec_hidden_dim, self.dec_hidden_dim)\r\n",
        "    self.v = nn.Linear(self.dec_hidden_dim, 1, bias=False)\r\n",
        "\r\n",
        "  def forward(self, hidden, enc_outputs, mask):\r\n",
        "    # hidden [bs, d_h_dim]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    bs, seq_len, _ = enc_outputs.shape\r\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\r\n",
        "    # hidden [bs, seq_len, d_h_dim]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    attn = torch.tanh(self.attention(torch.cat([hidden, enc_outputs], dim=2)))\r\n",
        "    # attn [bs, seq_len, d_h_dim]\r\n",
        "    energy = self.v(attn)\r\n",
        "    # energy [bs, seq_len, 1]\r\n",
        "    energy = energy.squeeze(2)\r\n",
        "    # energy [bs, seq_len]\r\n",
        "    energy = energy.masked_fill(mask == 0, -1e6)\r\n",
        "    return F.softmax(energy, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKMch61Vjd5Z"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, config, attention, enc_hidden_size):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(config.vocab_size, \r\n",
        "                                  config.emb_size, \r\n",
        "                                  padding_idx=config.pad_index)\r\n",
        "    self.dropout = nn.Dropout(config.dropout)\r\n",
        "    self.rnn = nn.GRU(config.emb_size + 2 * enc_hidden_size,\r\n",
        "                       config.hidden_size,\r\n",
        "                       config.num_layers,\r\n",
        "                       batch_first=True, \r\n",
        "                       dropout=config.dropout if config.num_layers > 1 else 0)\r\n",
        "    self.device = config.device\r\n",
        "    self.output_dim = config.vocab_size\r\n",
        "    self.attention = attention\r\n",
        "    self.enc_hidden_size = enc_hidden_size\r\n",
        "    self.output = nn.Linear(config.hidden_size + config.emb_size + (2 * enc_hidden_size), config.vocab_size)\r\n",
        "\r\n",
        "  def forward(self, trg_input, hidden, enc_outputs, mask):\r\n",
        "    trg_input = trg_input.unsqueeze(1)\r\n",
        "    # trg_input [bs, 1]\r\n",
        "    text_embedded = self.dropout(self.embedding(trg_input))\r\n",
        "    # text_embedded [bs, 1, emb_dim]\r\n",
        "\r\n",
        "    attn = self.attention(hidden, enc_outputs, mask)\r\n",
        "    # attn [bs, seq_len]\r\n",
        "    attn = attn.unsqueeze(1)\r\n",
        "    # attn [bs, 1, seq_len]\r\n",
        "    # enc_outputs [bs, seq_len, 2 * e_h_dim]\r\n",
        "    weights = torch.bmm(attn, enc_outputs)\r\n",
        "    # weights [bs, 1, 2 * e_h_dim]\r\n",
        "    rnn_input = torch.cat([text_embedded, weights], dim=2)\r\n",
        "    # rnn_input [bs, 1, 2 * e_h_dim + emb_dim]\r\n",
        "    hidden = hidden.unsqueeze(0)\r\n",
        "    # hidden [1, bs, h_dim]\r\n",
        "    outputs, hidden = self.rnn(rnn_input, hidden)\r\n",
        "    # outputs [bs, 1, d_h_dim]\r\n",
        "    # hidden_orig [1, bs, d_h_dim]\r\n",
        "    hidden = hidden.squeeze(0)\r\n",
        "    text_embedded = text_embedded.squeeze(1)\r\n",
        "    weights = weights.squeeze(1)\r\n",
        "\r\n",
        "    outputs = torch.cat([hidden, text_embedded, weights], dim=1)\r\n",
        "    # outputs [bs, 1, d_h_dim + emb_size + 2 * e_h_dim]\r\n",
        "    return self.output(outputs), hidden, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHP7lT8snvhV"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, encoder, decoder, device):\r\n",
        "    super().__init__()\r\n",
        "    self.encoder = encoder\r\n",
        "    self.decoder = decoder\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "  def _create_mask(self, src_text_lens):\r\n",
        "    bs = src_text_lens.size(0)\r\n",
        "    max_src_seq_len = torch.max(src_text_lens)\r\n",
        "    mask = torch.zeros(bs, max_src_seq_len)\r\n",
        "    for i in range(bs):\r\n",
        "      mask[i, :src_text_lens[i]] = 1\r\n",
        "    return mask\r\n",
        "\r\n",
        "  def forward(self, \r\n",
        "              src_text,\r\n",
        "              src_text_len,\r\n",
        "              trg_text,\r\n",
        "              trg_text_len,\r\n",
        "              teacher_forcing_ratio=0.5):\r\n",
        "    \r\n",
        "    enc_outputs, hidden = self.encoder(src_text, src_text_len)\r\n",
        "    bs, seq_len = trg_text.shape\r\n",
        "    dec_output_dim = decoder.output_dim\r\n",
        "    mask = self._create_mask(src_text_len)\r\n",
        "    mask = mask.to(self.device)\r\n",
        "\r\n",
        "    outputs = torch.zeros(bs, seq_len, dec_output_dim).to(self.device)\r\n",
        "\r\n",
        "    trg_input = trg_text[:, 0]\r\n",
        "\r\n",
        "    for t in range(1, seq_len):\r\n",
        "      prediction, hidden, attn = decoder(trg_input, hidden, enc_outputs, mask)\r\n",
        "\r\n",
        "      outputs[:, t, :] = prediction\r\n",
        "\r\n",
        "      top1 = torch.argmax(prediction, dim=1)\r\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "      next_token = trg_text[:, t]\r\n",
        "\r\n",
        "      trg_input = next_token if teacher_force else top1\r\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wpqPQb5Zhbz"
      },
      "source": [
        "encoder_config = Config(vocab_size=len(SRC.vocab),\r\n",
        "                        emb_size=512,\r\n",
        "                        hidden_size=256,\r\n",
        "                        num_layers=2,\r\n",
        "                        dropout=0.3,\r\n",
        "                        pad_index=SRC.vocab.stoi[SRC.pad_token],\r\n",
        "                        device=device)\r\n",
        "\r\n",
        "decoder_config = Config(vocab_size=len(TRG.vocab),\r\n",
        "                        emb_size=512,\r\n",
        "                        hidden_size=256,\r\n",
        "                        num_layers=1,\r\n",
        "                        dropout=0.3,\r\n",
        "                        pad_index=TRG.vocab.stoi[TRG.pad_token],\r\n",
        "                        device=device)\r\n",
        "\r\n",
        "encoder = Encoder(encoder_config)\r\n",
        "attention = Attention(encoder_config.hidden_size, decoder_config.hidden_size)\r\n",
        "decoder = Decoder(decoder_config, attention, encoder_config.hidden_size)\r\n",
        "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=decoder_config.pad_index).to(device)\r\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZYaHbxmZkvT"
      },
      "source": [
        "# with torch.no_grad():\r\n",
        "#   for batch in train_iterator:\r\n",
        "#     src_text, src_text_len = batch.de\r\n",
        "#     trg_text, trg_text_len = batch.en\r\n",
        "\r\n",
        "#     outputs = seq2seq(src_text, src_text_len, trg_text, trg_text_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNVaUvAAjZqJ"
      },
      "source": [
        "def train_epoch(model, iterator, optimizer, criterion, teacher_force=0.5):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  error = 0.\r\n",
        "  for batch in iterator:\r\n",
        "    optimizer.zero_grad()\r\n",
        "    \r\n",
        "    src_text, src_text_lens = batch.de\r\n",
        "    src_text_lens = src_text_lens.cpu()\r\n",
        "    trg_text, trg_text_lens = batch.en\r\n",
        "    trg_text_lens = trg_text_lens.cpu()\r\n",
        "\r\n",
        "    outputs = seq2seq(src_text, src_text_lens, trg_text, trg_text_lens, teacher_forcing_ratio=teacher_force)\r\n",
        "\r\n",
        "    outputs = outputs[:, 1:, :]\r\n",
        "    trg_text = trg_text[:, 1:]\r\n",
        "\r\n",
        "    outputs = outputs.contiguous()\r\n",
        "    trg_text = trg_text.contiguous()\r\n",
        "\r\n",
        "    batch_size, seq_len, output_dim = outputs.shape\r\n",
        "\r\n",
        "    outputs = outputs.view(-1, output_dim)\r\n",
        "    trg_text = trg_text.view(-1)\r\n",
        "\r\n",
        "    loss = criterion(outputs, trg_text)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "    error += loss.detach().cpu().numpy()\r\n",
        "\r\n",
        "  return error / len(iterator)\r\n",
        "\r\n",
        "\r\n",
        "def valid_epoch(model, iterator, criterion, teacher_force=0):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  error = 0.\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch in iterator:\r\n",
        "      \r\n",
        "      src_text, src_text_lens = batch.de\r\n",
        "      src_text_lens = src_text_lens.cpu()\r\n",
        "      trg_text, trg_text_lens = batch.en\r\n",
        "      trg_text_lens = trg_text_lens.cpu()\r\n",
        "\r\n",
        "      outputs = seq2seq(src_text, src_text_lens, trg_text, trg_text_lens, teacher_forcing_ratio=teacher_force)\r\n",
        "\r\n",
        "      outputs = outputs[:, 1:, :]\r\n",
        "      trg_text = trg_text[:, 1:]\r\n",
        "\r\n",
        "      outputs = outputs.contiguous()\r\n",
        "      trg_text = trg_text.contiguous()\r\n",
        "\r\n",
        "      batch_size, seq_len, output_dim = outputs.shape\r\n",
        "\r\n",
        "      outputs = outputs.reshape(-1, output_dim)\r\n",
        "      trg_text = trg_text.view(-1)\r\n",
        "\r\n",
        "      loss = criterion(outputs, trg_text)\r\n",
        "\r\n",
        "      error += loss.detach().cpu().numpy()\r\n",
        "\r\n",
        "  return error / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPJVoSv5yROF",
        "outputId": "cd89a83c-2262-46d2-e54e-30825d2bc87f"
      },
      "source": [
        "for i in range(10):\r\n",
        "  train_error = train_epoch(seq2seq, train_iterator, optimizer, criterion, teacher_force=0.5)\r\n",
        "  valid_error = valid_epoch(seq2seq, valid_iterator, criterion, teacher_force=0)\r\n",
        "  print(f'Epoch: {i + 1}, Train Error: {train_error}, Valid Error {valid_error}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Error: 5.1230571646439405, Valid Error 5.045970320701599\n",
            "Epoch: 2, Train Error: 4.186247896729854, Valid Error 4.4566733837127686\n",
            "Epoch: 3, Train Error: 3.5171332944903457, Valid Error 4.0057761669158936\n",
            "Epoch: 4, Train Error: 3.080598889735707, Valid Error 3.7955670952796936\n",
            "Epoch: 5, Train Error: 2.771454248512, Valid Error 3.7355512976646423\n",
            "Epoch: 6, Train Error: 2.5221352368070367, Valid Error 3.709387719631195\n",
            "Epoch: 7, Train Error: 2.3107156418917474, Valid Error 3.696047782897949\n",
            "Epoch: 8, Train Error: 2.199237852765803, Valid Error 3.6355701684951782\n",
            "Epoch: 9, Train Error: 2.0383083538005224, Valid Error 3.6049570441246033\n",
            "Epoch: 10, Train Error: 1.9273295559381183, Valid Error 3.6312490105628967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jj7AidXJRtm"
      },
      "source": [
        "# class LanguageModel:\r\n",
        "\r\n",
        "#   def __init__(self):\r\n",
        "#     self.key_sep = '&'\r\n",
        "#     self._occurances = {}\r\n",
        "\r\n",
        "#   def build(self, texts):\r\n",
        "#     for text in texts:\r\n",
        "#       self.update(text)\r\n",
        "\r\n",
        "#   def update(self, text):\r\n",
        "#     tokens = text.split()\r\n",
        "#     for i in range(len(tokens) - 1):\r\n",
        "#       key = f'{tokens[i]}{self.key_sep}{tokens[i + 1]}'\r\n",
        "#       if key not in self._occurances:\r\n",
        "#         self._occurances[key] = 1\r\n",
        "#       else:\r\n",
        "#         self._occurances[key] += 1\r\n",
        "  \r\n",
        "#   def get(self, word, next_word):\r\n",
        "#     key = f'{word}{self.key_sep}{next_word}'\r\n",
        "#     if key not in self._occurances:\r\n",
        "#       return 0\r\n",
        "#     else:\r\n",
        "#       return self._occurances[key] / len(self._occurances)\r\n",
        "\r\n",
        "\r\n",
        "# lang_model = LanguageModel()\r\n",
        "# corpus = [' '.join(example.en) for example in train_data.examples]\r\n",
        "# lang_model.build(corpus)\r\n",
        "\r\n",
        "# lang_model.get(word='two', next_word='men')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slr1D18olt_I"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token] \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\r\n",
        "\r\n",
        "    mask = torch.ByteTensor([1.] * len(src_indexes)).to(device)\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\r\n",
        "\r\n",
        "        attentions[i] = attention\r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT0PEEAvFTMH",
        "outputId": "ecee9efe-715e-4ffa-f9de-c9fc0d4b9119"
      },
      "source": [
        "index = 12\r\n",
        "\r\n",
        "origin_sentence = ' '.join(train_data.examples[index].de)\r\n",
        "target_sentence = ' '.join(train_data.examples[index].en)\r\n",
        "\r\n",
        "print(target_sentence)\r\n",
        "trg_tokens, attentions_scores = translate_sentence(origin_sentence, SRC, TRG, seq2seq, device)\r\n",
        "if trg_tokens[-1] == TRG.eos_token:\r\n",
        "  trg_tokens = trg_tokens[:-1]\r\n",
        "\r\n",
        "translated = ' '.join(trg_tokens)\r\n",
        "print(translated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a black dog and a spotted dog are fighting\n",
            "a black dog and a spotted dog fighting .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "kh1nTZwHFVIF",
        "outputId": "b745b15d-362d-4f29-fc84-771e1b5c2008"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "def show_attention(origin, translated, attention):  \r\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\r\n",
        "    \r\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\r\n",
        "\r\n",
        "    origin = origin.split()\r\n",
        "    translated = translated.split()\r\n",
        "\r\n",
        "    ax.set_xticks(range(len(origin) + 2))\r\n",
        "    ax.set_yticks(range(len(translated) + 1))\r\n",
        "\r\n",
        "    ax.set_xticklabels(['<sos>'] + origin + ['<eos>'], rotation=45)\r\n",
        "    ax.set_yticklabels(translated + ['<eos>'])\r\n",
        "\r\n",
        "    ax.imshow(attention)\r\n",
        "\r\n",
        "\r\n",
        "show_attention(origin_sentence, translated, attentions_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX6Ch4Z89V7_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}